{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bdeva\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\bdeva\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bdeva\\anaconda3\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bdeva\\anaconda3\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"c:\\Users\\bdeva\\anaconda3\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.8002\n",
      "Cross-Validation Scores: [0.79971388 0.81831187 0.89270386 0.89985694 0.91977077]\n",
      "Mean Cross-Validation Accuracy: 0.8661\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Step 1: Load your dataset\n",
    "df = pd.read_csv('new_descriptors.csv')  # Replace 'your_file.csv' with your actual file name\n",
    "X = df.drop('Target', axis=1)  # Replace 'target_column' with the name of your target column\n",
    "y = df['Target']\n",
    "\n",
    "# Step 2: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 3: Apply SMOTE to handle class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 4: Initialize the Random Forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Step 5: Apply SelectFromModel for feature selection\n",
    "selector = SelectFromModel(estimator=rf)\n",
    "selector.fit(X_train_smote, y_train_smote)\n",
    "X_train_selected = selector.transform(X_train_smote)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# Step 6: Train the Random Forest model on the selected features\n",
    "rf.fit(X_train_selected, y_train_smote)\n",
    "y_pred = rf.predict(X_test_selected)\n",
    "\n",
    "# Step 7: Evaluate the model accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Step 8: Perform cross-validation to evaluate the model\n",
    "cross_val_scores = cross_val_score(rf, X_train_selected, y_train_smote, cv=5)\n",
    "print(f\"Cross-Validation Scores: {cross_val_scores}\")\n",
    "print(f\"Mean Cross-Validation Accuracy: {cross_val_scores.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile Threshold Value: 0.0009058010038792962\n",
      "Selected Features:\n",
      "Index(['nAcid', 'VE1_A', 'VE2_A', 'nF', 'ATS6dv', 'ATS8dv', 'ATS3d', 'ATS2s',\n",
      "       'ATS5s', 'ATS6s',\n",
      "       ...\n",
      "       'piPC9', 'TpiPC10', 'bpol', 'nG12FaHRing', 'TopoPSA(NO)', 'TopoPSA',\n",
      "       'GGI3', 'GGI4', 'GGI6', 'GGI10'],\n",
      "      dtype='object', length=363)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bdeva\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\bdeva\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bdeva\\anaconda3\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bdeva\\anaconda3\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"c:\\Users\\bdeva\\anaconda3\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.83834049 0.85121602 0.87982833 0.89699571 0.89398281]\n",
      "Mean Cross-Validation Accuracy: 0.8720726703313371\n",
      "Rows predicted as inhibitors:\n",
      "      nAcid  nBase    SpAbs_A   SpMax_A  SpDiam_A     SpAD_A   SpMAD_A  \\\n",
      "325       0      3  42.760646  2.508523  5.015985  42.760646  1.257666   \n",
      "2480      0      0  36.286579  2.462812  4.918740  36.286579  1.251261   \n",
      "1862      0      0  39.235488  2.421269  4.816843  39.235488  1.307850   \n",
      "1637      0      1  56.541246  2.845339  5.459661  56.541246  1.229158   \n",
      "2374      0      2  37.725101  2.444531  4.883653  37.725101  1.300866   \n",
      "...     ...    ...        ...       ...       ...        ...       ...   \n",
      "1647      1      0  41.585356  2.511985  5.023970  41.585356  1.223099   \n",
      "1949      0      0  43.175258  2.509731  4.936039  43.175258  1.308341   \n",
      "2271      0      0  41.999240  2.633193  5.244116  41.999240  1.235272   \n",
      "2965      0      0  36.921710  2.578320  5.156639  36.921710  1.273162   \n",
      "944       0      1  42.881081  2.595466  5.097480  42.881081  1.261208   \n",
      "\n",
      "       LogEE_A     VE1_A     VE2_A  ...      TSRW10          MW       AMW  \\\n",
      "325   4.460046  4.618782  0.135847  ...   84.285631  461.222703  7.439076   \n",
      "2480  4.287808  4.481934  0.154549  ...   72.441094  426.122498  8.522450   \n",
      "1862  4.333920  4.462259  0.148742  ...   79.192596  403.180838  7.753478   \n",
      "1637  4.805168  4.635824  0.100779  ...  107.585066  646.455702  5.985701   \n",
      "2374  4.303736  4.790211  0.165180  ...   78.192972  394.236876  6.681981   \n",
      "...        ...       ...       ...  ...         ...         ...       ...   \n",
      "1647  4.438644  4.674039  0.137472  ...   70.415546  511.083191  9.292422   \n",
      "1949  4.447059  4.787228  0.145068  ...   85.410773  450.186732  7.898013   \n",
      "2271  4.489929  4.942009  0.145353  ...   91.438888  523.064348  9.869139   \n",
      "2965  4.289065  4.285544  0.147777  ...   65.009126  437.106372  8.247290   \n",
      "944   4.481654  4.280184  0.125888  ...   90.719892  513.206420  7.331520   \n",
      "\n",
      "      WPath  WPol  Zagreb1  Zagreb2   mZagreb1  mZagreb2  Target  \n",
      "325    3532    59      184      220  12.645833  7.319444       1  \n",
      "2480   2165    50      152      177  10.541667  6.222222       1  \n",
      "1862   2885    46      158      185   9.111111  6.611111       1  \n",
      "1637   7693   100      274      351  19.208333  9.361111       1  \n",
      "2374   2371    46      154      182   8.861111  6.388889       1  \n",
      "...     ...   ...      ...      ...        ...       ...     ...  \n",
      "1647   3218    57      176      206  13.534722  7.388889       0  \n",
      "1949   3310    56      182      220  10.194444  7.138889       1  \n",
      "2271   3087    70      194      243  14.138889  7.055556       1  \n",
      "2965   2066    54      152      184  10.541667  6.534722       0  \n",
      "944    3539    61      188      228  12.826389  7.250000       1  \n",
      "\n",
      "[793 rows x 1452 columns]\n",
      "\n",
      "Random Forest with Feature Importance Selection and SMOTE\n",
      "Overall Accuracy: 0.7992459943449576\n",
      "Precision: 0.7972049009232263\n",
      "F1 Score: 0.7981612479012257\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.60      0.61       277\n",
      "           1       0.86      0.87      0.86       784\n",
      "\n",
      "    accuracy                           0.80      1061\n",
      "   macro avg       0.74      0.73      0.74      1061\n",
      "weighted avg       0.80      0.80      0.80      1061\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv('new_descriptors.csv')\n",
    "\n",
    "# Extract features and target\n",
    "X = df.drop(columns=['Target'])\n",
    "y = df['Target']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the Random Forest model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Feature Importance based selection\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Determine the threshold as a quantile (e.g., 75th percentile)\n",
    "quantile = 0.75\n",
    "threshold_value = np.quantile(importances, quantile)\n",
    "print(f\"Quantile Threshold Value: {threshold_value}\")\n",
    "\n",
    "# Feature selection with SelectFromModel using the quantile threshold\n",
    "selector = SelectFromModel(rf, threshold=threshold_value, prefit=True)\n",
    "X_train_selected = selector.transform(X_train_scaled)\n",
    "X_test_selected = selector.transform(X_test_scaled)\n",
    "\n",
    "# Get the mask of selected features\n",
    "selected_features_mask = selector.get_support()\n",
    "selected_features = X.columns[selected_features_mask]\n",
    "\n",
    "print(\"Selected Features:\")\n",
    "print(selected_features)\n",
    "\n",
    "# Apply SMOTE to handle class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_selected, y_train)\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
    "                           param_grid=param_grid,\n",
    "                           cv=5,\n",
    "                           n_jobs=-1,\n",
    "                           scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train_smote, y_train_smote)\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate model with cross-validation\n",
    "cross_val_scores = cross_val_score(best_rf, X_train_smote, y_train_smote, cv=5, scoring='accuracy')\n",
    "print(f\"Cross-Validation Accuracy Scores: {cross_val_scores}\")\n",
    "print(f\"Mean Cross-Validation Accuracy: {cross_val_scores.mean()}\")\n",
    "\n",
    "# Train the final model\n",
    "best_rf.fit(X_train_smote, y_train_smote)\n",
    "y_pred = best_rf.predict(X_test_selected)\n",
    "\n",
    "# Identify rows predicted as inhibitors\n",
    "# Assume inhibitors are labeled as 1; adjust if necessary\n",
    "inhibitor_label = 1\n",
    "inhibitor_predictions = X_test_selected[y_pred == inhibitor_label]\n",
    "\n",
    "# Map predictions back to original dataframe\n",
    "inhibitor_indices = np.where(y_pred == inhibitor_label)[0]\n",
    "inhibitor_rows = df.iloc[X_test.index[inhibitor_indices]]\n",
    "\n",
    "# Print identified rows\n",
    "print(\"Rows predicted as inhibitors:\")\n",
    "print(inhibitor_rows)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nRandom Forest with Feature Importance Selection and SMOTE\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Overall Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='weighted'))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert selected features to a DataFrame and save as CSV\n",
    "selected_features_df = pd.DataFrame(selected_features, columns=['Selected_Features'])\n",
    "selected_features_df.to_csv('selected_features_rf.csv', index=False)\n",
    "\n",
    "# Save rows predicted as inhibitors to a CSV\n",
    "inhibitor_rows.to_csv('rows_predicted_as_inhibitors_rf.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
